{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_sentence_transformer.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('val_sentence_transformer.pkl', 'rb') as f:\n",
    "    val = pickle.load(f)\n",
    "with open('test_sentence_transformer.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('test.json', encoding = 'utf8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "conversations = []\n",
    "summaries = []\n",
    "for i in range(0, len(data)):\n",
    "    if len(data[i]['dialogue'].split('\\r\\n')) > 1:\n",
    "        sentences = data[i]['dialogue'].split('\\r\\n')\n",
    "    else:\n",
    "        sentences = data[i]['dialogue'].split('\\n')\n",
    "\n",
    "    conversations.append(sentences)\n",
    "    summaries.append(data[i]['summary'].strip('\\n').replace('\\r\\nt', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "length = []\n",
    "for i in range(0, len(train)):\n",
    "    length.append(len(train[i]))\n",
    "for i in range(0, len(val)):\n",
    "    length.append(len(val[i]))\n",
    "for i in range(0, len(test)):\n",
    "    length.append(len(test[i]))\n",
    "X = []\n",
    "for i in range(0, len(train)):\n",
    "    for j in range(0, len(train[i])):\n",
    "        X.append(np.array(train[i][j]))\n",
    "for i in range(0, len(val)):\n",
    "    for j in range(0,len(val[i])):\n",
    "        X.append(np.array(val[i][j]))\n",
    "for i in range(0, len(test)):\n",
    "    for j in range(0, len(test[i])):\n",
    "        X.append(np.array(test[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remodel = hmm.GaussianHMM(n_components=4, n_iter = 50, covariance_type = 'diag', verbose = True, init_params=\"cm\", params=\"cmts\")\n",
    "remodel.startprob_ = np.array([1, 0.0, 0.0, 0.0])\n",
    "remodel.transmat_ = np.array([\n",
    "                 [0.33, 0.34, 0.33, 0],\n",
    "                 [0.0, 0.33, 0.34, 0.33],\n",
    "                 [0.0, 0.0, 0.5, 0.5],\n",
    "                 [0.0, 0.0, 0.0, 1.0]]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remodel.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33, 0.34, 0.33, 0.  ],\n",
       "       [0.  , 0.33, 0.34, 0.33],\n",
       "       [0.  , 0.  , 0.5 , 0.5 ],\n",
       "       [0.  , 0.  , 0.  , 1.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remodel.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -272805.13153256             +nan\n",
      "         2 -264097.95087766   +8707.18065490\n",
      "         3 -263840.90952861    +257.04134906\n",
      "         4 -263782.24137520     +58.66815340\n",
      "         5 -263781.90776199      +0.33361322\n",
      "         6 -263778.10659836      +3.80116362\n",
      "         7 -263768.90956129      +9.19703707\n",
      "         8 -263768.90846337      +0.00109792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianHMM(init_params='cm', n_components=4, n_iter=50, params='cmts',\n",
       "            verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remodel.fit(X, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82242995, 0.08878503, 0.08878502, 0.        ],\n",
       "       [0.        , 0.84848478, 0.10101014, 0.05050507],\n",
       "       [0.        , 0.        , 0.87323942, 0.12676058],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remodel.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remodel.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_convs(profix):\n",
    "    sent_label = []\n",
    "    with open(profix + '_sentence_transformer.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    for i in range(0, len(data)):\n",
    "        labels = remodel.decode(np.array(data[i]))[1]\n",
    "        sent_label.append(labels)\n",
    "    \n",
    "    with open(profix + '_sent_trans_cons_label.pkl', 'wb') as f:\n",
    "        pickle.dump(sent_label, f)\n",
    "    return sent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = encode_convs('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = encode_convs('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = encode_convs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
